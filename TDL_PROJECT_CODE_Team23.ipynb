{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Data set and Exploratory Data Analysis\n"
      ],
      "metadata": {
        "id": "WVsJ57uRB7a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQfmW7fd6nDC",
        "outputId": "874b996b-53ec-4af9-c4cb-4e2463ee7d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title  \\\n",
            "0  9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1  Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2  R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3  4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4  tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "\n",
            "           publishedAt                 channelId        channelTitle  \\\n",
            "0  2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1   2023-11-30 7:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2   2023-11-30 6:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3   2023-11-30 2:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4  2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "\n",
            "   categoryId         trending_date  \\\n",
            "0          24  2023-12-01T00:00:00Z   \n",
            "1          24  2023-12-01T00:00:00Z   \n",
            "2          27  2023-12-01T00:00:00Z   \n",
            "3          22  2023-12-01T00:00:00Z   \n",
            "4          23  2023-12-01T00:00:00Z   \n",
            "\n",
            "                                                tags  view_count   likes  \\\n",
            "0  sidharth tv|sidharthtv|sidharth tv channel|sid...      599086   12871   \n",
            "1  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...     1573530   31063   \n",
            "2  neet|neet 2024|neet batch|neet batch pw|neet b...       93820    5421   \n",
            "3  shopping in london|london shopping|sourav josh...     4151330  301624   \n",
            "4  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...      137731    3473   \n",
            "\n",
            "   comment_count                                  thumbnail_link  \\\n",
            "0            172  https://i.ytimg.com/vi/9TFJ9fSirB8/default.jpg   \n",
            "1            425  https://i.ytimg.com/vi/Sm7fButI6lU/default.jpg   \n",
            "2            522  https://i.ytimg.com/vi/R-sh22bAAA4/default.jpg   \n",
            "3           8074  https://i.ytimg.com/vi/4u92ooRjKzc/default.jpg   \n",
            "4            101  https://i.ytimg.com/vi/tU6O2XBOjro/default.jpg   \n",
            "\n",
            "   comments_disabled  ratings_disabled  Subscriber_Count  Is_Live_Stream  \\\n",
            "0              False             False         8250000.0               0   \n",
            "1              False             False        22100000.0               0   \n",
            "2              False             False         2680000.0               0   \n",
            "3              False             False        23600000.0               0   \n",
            "4              False             False          946000.0               0   \n",
            "\n",
            "                                        Top_Comments  \n",
            "0  ['‡¨∏‡¨§‡¨∞‡≠á ‡¨Æ‡¨ú‡¨æ ‡¨Ü‡¨∏‡¨ø‡¨ó‡¨≤‡¨æ üî•üî•', 'My Favourite serial ‚ù§Ô∏è...  \n",
            "1  ['Started  watching this  serial only for swam...  \n",
            "2  ['üìö Aarambh NEET 2024 : https://physicswallah....  \n",
            "3  ['23.5 million the love and support we give is...  \n",
            "4  ['Very funny! Shri being like Mr Bean for this...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/TDL_DATASET.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic pre-processing steps such as checking for missing values and datatypes of the columns\n"
      ],
      "metadata": {
        "id": "S55NxAzVClyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remove rows with any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Check the shape of the DataFrame after removing missing values and duplicates\n",
        "print(\"Shape after removing missing values and duplicates:\", df.shape)\n",
        "\n",
        "# Check the data types of each column\n",
        "print(df.dtypes)\n",
        "\n",
        "# Convert 'publishedAt' and 'trending_date' to datetime\n",
        "df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
        "df['trending_date'] = pd.to_datetime(df['trending_date'])\n",
        "\n",
        "# Display the first few rows of the DataFrame after preprocessing\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXfW-eOi8a-p",
        "outputId": "0fd73b49-38b2-4a27-c7e7-bf61b5201cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video_id              0\n",
            "title                 0\n",
            "publishedAt           0\n",
            "channelId             0\n",
            "channelTitle          0\n",
            "categoryId            0\n",
            "trending_date         0\n",
            "tags                  0\n",
            "view_count            0\n",
            "likes                 0\n",
            "comment_count         0\n",
            "thumbnail_link        0\n",
            "comments_disabled     0\n",
            "ratings_disabled      0\n",
            "Subscriber_Count     23\n",
            "Is_Live_Stream        0\n",
            "Top_Comments          0\n",
            "dtype: int64\n",
            "Shape after removing missing values and duplicates: (1421, 17)\n",
            "video_id              object\n",
            "title                 object\n",
            "publishedAt           object\n",
            "channelId             object\n",
            "channelTitle          object\n",
            "categoryId             int64\n",
            "trending_date         object\n",
            "tags                  object\n",
            "view_count             int64\n",
            "likes                  int64\n",
            "comment_count          int64\n",
            "thumbnail_link        object\n",
            "comments_disabled       bool\n",
            "ratings_disabled        bool\n",
            "Subscriber_Count     float64\n",
            "Is_Live_Stream         int64\n",
            "Top_Comments          object\n",
            "dtype: object\n",
            "      video_id                                              title  \\\n",
            "0  9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1  Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2  R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3  4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4  tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "\n",
            "          publishedAt                 channelId        channelTitle  \\\n",
            "0 2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1 2023-11-30 07:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2 2023-11-30 06:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3 2023-11-30 02:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4 2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "\n",
            "   categoryId             trending_date  \\\n",
            "0          24 2023-12-01 00:00:00+00:00   \n",
            "1          24 2023-12-01 00:00:00+00:00   \n",
            "2          27 2023-12-01 00:00:00+00:00   \n",
            "3          22 2023-12-01 00:00:00+00:00   \n",
            "4          23 2023-12-01 00:00:00+00:00   \n",
            "\n",
            "                                                tags  view_count   likes  \\\n",
            "0  sidharth tv|sidharthtv|sidharth tv channel|sid...      599086   12871   \n",
            "1  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...     1573530   31063   \n",
            "2  neet|neet 2024|neet batch|neet batch pw|neet b...       93820    5421   \n",
            "3  shopping in london|london shopping|sourav josh...     4151330  301624   \n",
            "4  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...      137731    3473   \n",
            "\n",
            "   comment_count                                  thumbnail_link  \\\n",
            "0            172  https://i.ytimg.com/vi/9TFJ9fSirB8/default.jpg   \n",
            "1            425  https://i.ytimg.com/vi/Sm7fButI6lU/default.jpg   \n",
            "2            522  https://i.ytimg.com/vi/R-sh22bAAA4/default.jpg   \n",
            "3           8074  https://i.ytimg.com/vi/4u92ooRjKzc/default.jpg   \n",
            "4            101  https://i.ytimg.com/vi/tU6O2XBOjro/default.jpg   \n",
            "\n",
            "   comments_disabled  ratings_disabled  Subscriber_Count  Is_Live_Stream  \\\n",
            "0              False             False         8250000.0               0   \n",
            "1              False             False        22100000.0               0   \n",
            "2              False             False         2680000.0               0   \n",
            "3              False             False        23600000.0               0   \n",
            "4              False             False          946000.0               0   \n",
            "\n",
            "                                        Top_Comments  \n",
            "0  ['‡¨∏‡¨§‡¨∞‡≠á ‡¨Æ‡¨ú‡¨æ ‡¨Ü‡¨∏‡¨ø‡¨ó‡¨≤‡¨æ üî•üî•', 'My Favourite serial ‚ù§Ô∏è...  \n",
            "1  ['Started  watching this  serial only for swam...  \n",
            "2  ['üìö Aarambh NEET 2024 : https://physicswallah....  \n",
            "3  ['23.5 million the love and support we give is...  \n",
            "4  ['Very funny! Shri being like Mr Bean for this...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping of category name and ID\n"
      ],
      "metadata": {
        "id": "drja1pcSDYzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the category ID to category name mapping\n",
        "category_mapping = {\n",
        "    \"1\": \"Film & Animation\",\n",
        "    \"2\": \"Autos & Vehicles\",\n",
        "    \"10\": \"Music\",\n",
        "    \"15\": \"Pets & Animals\",\n",
        "    \"17\": \"Sports\",\n",
        "    \"18\": \"Short Movies\",\n",
        "    \"19\": \"Travel & Events\",\n",
        "    \"20\": \"Gaming\",\n",
        "    \"21\": \"Videoblogging\",\n",
        "    \"22\": \"People & Blogs\",\n",
        "    \"23\": \"Comedy\",\n",
        "    \"24\": \"Entertainment\",\n",
        "    \"25\": \"News & Politics\",\n",
        "    \"26\": \"Howto & Style\",\n",
        "    \"27\": \"Education\",\n",
        "    \"28\": \"Science & Technology\",\n",
        "    \"30\": \"Movies\",\n",
        "    \"31\": \"Anime/Animation\",\n",
        "    \"32\": \"Action/Adventure\",\n",
        "    \"33\": \"Classics\",\n",
        "    \"34\": \"Comedy\",\n",
        "    \"35\": \"Documentary\",\n",
        "    \"36\": \"Drama\",\n",
        "    \"37\": \"Family\",\n",
        "    \"38\": \"Foreign\",\n",
        "    \"39\": \"Horror\",\n",
        "    \"40\": \"Sci-Fi/Fantasy\",\n",
        "    \"41\": \"Thriller\",\n",
        "    \"42\": \"Shorts\",\n",
        "    \"43\": \"Shows\",\n",
        "    \"44\": \"Trailers\",\n",
        "    # Add missing category IDs here\n",
        "}\n",
        "\n",
        "# Map category IDs to category names and add a new column 'category_name' to the DataFrame\n",
        "df['category_name'] = df['categoryId'].astype(str).map(category_mapping)\n",
        "\n",
        "# Display the rows where 'category_name' is NaN to identify missing category IDs\n",
        "print(df[df['category_name'].isnull()])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnYUKAz1CRPc",
        "outputId": "ea9ba846-d8fa-433b-8200-35fb4094a79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [video_id, title, publishedAt, channelId, channelTitle, categoryId, trending_date, tags, view_count, likes, comment_count, thumbnail_link, comments_disabled, ratings_disabled, Subscriber_Count, Is_Live_Stream, Top_Comments, category_name]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpcDOAFrDTPl",
        "outputId": "0b4c0b96-253e-4879-c1e5-20c4158501a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title  \\\n",
            "0  9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1  Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2  R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3  4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4  tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "\n",
            "          publishedAt                 channelId        channelTitle  \\\n",
            "0 2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1 2023-11-30 07:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2 2023-11-30 06:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3 2023-11-30 02:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4 2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "\n",
            "   categoryId             trending_date  \\\n",
            "0          24 2023-12-01 00:00:00+00:00   \n",
            "1          24 2023-12-01 00:00:00+00:00   \n",
            "2          27 2023-12-01 00:00:00+00:00   \n",
            "3          22 2023-12-01 00:00:00+00:00   \n",
            "4          23 2023-12-01 00:00:00+00:00   \n",
            "\n",
            "                                                tags  view_count   likes  \\\n",
            "0  sidharth tv|sidharthtv|sidharth tv channel|sid...      599086   12871   \n",
            "1  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...     1573530   31063   \n",
            "2  neet|neet 2024|neet batch|neet batch pw|neet b...       93820    5421   \n",
            "3  shopping in london|london shopping|sourav josh...     4151330  301624   \n",
            "4  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...      137731    3473   \n",
            "\n",
            "   comment_count                                  thumbnail_link  \\\n",
            "0            172  https://i.ytimg.com/vi/9TFJ9fSirB8/default.jpg   \n",
            "1            425  https://i.ytimg.com/vi/Sm7fButI6lU/default.jpg   \n",
            "2            522  https://i.ytimg.com/vi/R-sh22bAAA4/default.jpg   \n",
            "3           8074  https://i.ytimg.com/vi/4u92ooRjKzc/default.jpg   \n",
            "4            101  https://i.ytimg.com/vi/tU6O2XBOjro/default.jpg   \n",
            "\n",
            "   comments_disabled  ratings_disabled  Subscriber_Count  Is_Live_Stream  \\\n",
            "0              False             False         8250000.0               0   \n",
            "1              False             False        22100000.0               0   \n",
            "2              False             False         2680000.0               0   \n",
            "3              False             False        23600000.0               0   \n",
            "4              False             False          946000.0               0   \n",
            "\n",
            "                                        Top_Comments   category_name  \n",
            "0  ['‡¨∏‡¨§‡¨∞‡≠á ‡¨Æ‡¨ú‡¨æ ‡¨Ü‡¨∏‡¨ø‡¨ó‡¨≤‡¨æ üî•üî•', 'My Favourite serial ‚ù§Ô∏è...   Entertainment  \n",
            "1  ['Started  watching this  serial only for swam...   Entertainment  \n",
            "2  ['üìö Aarambh NEET 2024 : https://physicswallah....       Education  \n",
            "3  ['23.5 million the love and support we give is...  People & Blogs  \n",
            "4  ['Very funny! Shri being like Mr Bean for this...          Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating the mapping of categories from IN_category_id.json\n"
      ],
      "metadata": {
        "id": "owiB_v7qEHwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file containing category information\n",
        "with open('/content/IN_category_id.json', 'r') as f:\n",
        "    category_data = json.load(f)\n",
        "\n",
        "# Extract category mappings from the JSON data\n",
        "category_mapping_json = {}\n",
        "for item in category_data['items']:\n",
        "    category_id = item['id']\n",
        "    category_name = item['snippet']['title']\n",
        "    category_mapping_json[category_id] = category_name\n",
        "\n",
        "# Validate category IDs and names from your dataset\n",
        "for category_id, category_name in category_mapping.items():\n",
        "    if category_id not in category_mapping_json:\n",
        "        print(f\"Category ID {category_id} not found in the JSON file\")\n",
        "    elif category_mapping_json[category_id] != category_name:\n",
        "        print(f\"Mismatch for Category ID {category_id}: JSON title - {category_mapping_json[category_id]}, Dataset title - {category_name}\")\n",
        "    else:\n",
        "        print(f\"Category ID {category_id} validated successfully\")\n",
        "\n",
        "# Additional validation for categories present in the JSON file but not in your dataset\n",
        "for category_id, category_name in category_mapping_json.items():\n",
        "    if category_id not in category_mapping:\n",
        "        print(f\"Category ID {category_id} - {category_name} present in JSON file but not in the dataset\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZoSbTcsFh9Y",
        "outputId": "447458b0-bc7e-4f27-8c86-8872e32e7b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category ID 1 validated successfully\n",
            "Category ID 2 validated successfully\n",
            "Category ID 10 validated successfully\n",
            "Category ID 15 validated successfully\n",
            "Category ID 17 validated successfully\n",
            "Category ID 18 validated successfully\n",
            "Category ID 19 validated successfully\n",
            "Category ID 20 validated successfully\n",
            "Category ID 21 validated successfully\n",
            "Category ID 22 validated successfully\n",
            "Category ID 23 validated successfully\n",
            "Category ID 24 validated successfully\n",
            "Category ID 25 validated successfully\n",
            "Category ID 26 validated successfully\n",
            "Category ID 27 validated successfully\n",
            "Category ID 28 validated successfully\n",
            "Category ID 30 validated successfully\n",
            "Category ID 31 validated successfully\n",
            "Category ID 32 validated successfully\n",
            "Category ID 33 validated successfully\n",
            "Category ID 34 validated successfully\n",
            "Category ID 35 validated successfully\n",
            "Category ID 36 validated successfully\n",
            "Category ID 37 validated successfully\n",
            "Category ID 38 validated successfully\n",
            "Category ID 39 validated successfully\n",
            "Category ID 40 validated successfully\n",
            "Category ID 41 validated successfully\n",
            "Category ID 42 validated successfully\n",
            "Category ID 43 validated successfully\n",
            "Category ID 44 validated successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoding categories to convert them to numerical values\n"
      ],
      "metadata": {
        "id": "XB06FIEPE32D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding for 'category_name'\n",
        "df_encoded = pd.get_dummies(df, columns=['category_name'], prefix='', prefix_sep='')\n",
        "\n",
        "# Drop the original 'categoryid' column\n",
        "df_encoded.drop('categoryId', axis=1, inplace=True)\n",
        "\n",
        "# Display the first few rows of the encoded DataFrame\n",
        "print(df_encoded.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc9BdqDRF4GL",
        "outputId": "9e30a6d4-ddd9-4bad-86a3-d2a7cde640b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title  \\\n",
            "0  9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1  Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2  R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3  4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4  tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "\n",
            "          publishedAt                 channelId        channelTitle  \\\n",
            "0 2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1 2023-11-30 07:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2 2023-11-30 06:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3 2023-11-30 02:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4 2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "\n",
            "              trending_date  \\\n",
            "0 2023-12-01 00:00:00+00:00   \n",
            "1 2023-12-01 00:00:00+00:00   \n",
            "2 2023-12-01 00:00:00+00:00   \n",
            "3 2023-12-01 00:00:00+00:00   \n",
            "4 2023-12-01 00:00:00+00:00   \n",
            "\n",
            "                                                tags  view_count   likes  \\\n",
            "0  sidharth tv|sidharthtv|sidharth tv channel|sid...      599086   12871   \n",
            "1  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...     1573530   31063   \n",
            "2  neet|neet 2024|neet batch|neet batch pw|neet b...       93820    5421   \n",
            "3  shopping in london|london shopping|sourav josh...     4151330  301624   \n",
            "4  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...      137731    3473   \n",
            "\n",
            "   comment_count  ... Entertainment  Film & Animation  Gaming  Howto & Style  \\\n",
            "0            172  ...             1                 0       0              0   \n",
            "1            425  ...             1                 0       0              0   \n",
            "2            522  ...             0                 0       0              0   \n",
            "3           8074  ...             0                 0       0              0   \n",
            "4            101  ...             0                 0       0              0   \n",
            "\n",
            "   Music News & Politics  People & Blogs  Science & Technology  Sports  \\\n",
            "0      0               0               0                     0       0   \n",
            "1      0               0               0                     0       0   \n",
            "2      0               0               0                     0       0   \n",
            "3      0               0               1                     0       0   \n",
            "4      0               0               0                     0       0   \n",
            "\n",
            "   Travel & Events  \n",
            "0                0  \n",
            "1                0  \n",
            "2                0  \n",
            "3                0  \n",
            "4                0  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export df to CSV\n",
        "df.to_csv('/content/dataset_category_name.csv', index=False)\n",
        "\n",
        "# Export df_encoded to CSV\n",
        "df_encoded.to_csv('/content/dataset_category_encoded.csv', index=False)\n"
      ],
      "metadata": {
        "id": "p27FwxmLHHyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using Textblob on the top 10 comments per video to analyse the overall audience sentiment and to arrive at a Sentiment score"
      ],
      "metadata": {
        "id": "zsKPUlyMFDJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the existing DataFrame\n",
        "existing_df = pd.read_csv('/content/dataset_category_encoded.csv')\n",
        "# Define the number of comments to analyze for each video\n",
        "comments_per_video = 10\n",
        "batch_size = 10000  # Adjust as needed\n",
        "\n",
        "# Function to perform sentiment analysis on comments\n",
        "def analyze_sentiment(comments):\n",
        "    sentiment_scores = []\n",
        "    for comment in comments:\n",
        "        if comment:\n",
        "            analysis = TextBlob(comment)\n",
        "            sentiment_scores.append(analysis.sentiment.polarity)\n",
        "        else:\n",
        "            sentiment_scores.append(None)\n",
        "    return sentiment_scores\n",
        "\n",
        "# Check if 'Sentiment_Scores' column already exists\n",
        "if 'Sentiment_Scores' not in existing_df.columns:\n",
        "    existing_df['Sentiment_Scores'] = None\n",
        "\n",
        "# Iterate over the rows in the existing DataFrame and update the 'Sentiment_Scores' column\n",
        "for index, row in existing_df.iterrows():\n",
        "    top_comments_str = row['Top_Comments']\n",
        "\n",
        "    # Check for NaN values before splitting\n",
        "    if not pd.isna(top_comments_str):\n",
        "        # Split the comma-separated string into a list of comments\n",
        "        top_comments = [comment.strip() for comment in top_comments_str.split(',')]\n",
        "\n",
        "        # Perform sentiment analysis\n",
        "        sentiment_scores = analyze_sentiment(top_comments)\n",
        "\n",
        "        # Calculate the mean sentiment score\n",
        "        mean_sentiment = pd.Series(sentiment_scores).mean()\n",
        "\n",
        "        # Update the 'Sentiment_Scores' column\n",
        "        existing_df.at[index, 'Sentiment_Scores'] = mean_sentiment\n",
        "\n",
        "# Save the updated DataFrame back to the same CSV file\n",
        "existing_df.to_csv('/content/dataset_category_encoded.csv', index=False)\n"
      ],
      "metadata": {
        "id": "kU38oSDkWSSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing video tags to check for frequency"
      ],
      "metadata": {
        "id": "VrAHUzNFInCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the existing DataFrame\n",
        "existing_df = pd.read_csv('/content/TDL DATASET - Sheet1.csv')\n",
        "\n",
        "# Function to preprocess tags\n",
        "def preprocess_tags(tags):\n",
        "    if pd.isna(tags):\n",
        "        return ''\n",
        "    # Convert tags to lowercase and replace '|' with space\n",
        "    return tags.lower().replace('|', ' ')\n",
        "\n",
        "# Preprocess the tags column\n",
        "existing_df['Processed_Tags'] = existing_df['tags'].apply(preprocess_tags)\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=100)  # Adjust max_features as needed\n",
        "\n",
        "# Fit and transform the processed tags to numerical features\n",
        "tag_features = vectorizer.fit_transform(existing_df['Processed_Tags']).toarray()\n",
        "\n",
        "# Create a DataFrame for the tag features\n",
        "tag_feature_names = vectorizer.get_feature_names_out()\n",
        "tag_features_df = pd.DataFrame(tag_features, columns=tag_feature_names)\n",
        "\n",
        "# Concatenate the tag features with the existing DataFrame\n",
        "existing_df = pd.concat([existing_df, tag_features_df], axis=1)\n",
        "\n",
        "# Calculate the sum of tag occurrences for each video\n",
        "existing_df['Tag_Score'] = existing_df[tag_feature_names].sum(axis=1)\n",
        "\n",
        "# Display the updated DataFrame with the tag features and score\n",
        "print(existing_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJG1qKwjINda",
        "outputId": "d3b3905a-1f06-4a06-f315-d4fd53438f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title  \\\n",
            "0  9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1  Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2  R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3  4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4  tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "\n",
            "           publishedAt                 channelId        channelTitle  \\\n",
            "0  2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1   2023-11-30 7:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2   2023-11-30 6:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3   2023-11-30 2:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4  2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "\n",
            "   categoryId         trending_date  \\\n",
            "0          24  2023-12-01T00:00:00Z   \n",
            "1          24  2023-12-01T00:00:00Z   \n",
            "2          27  2023-12-01T00:00:00Z   \n",
            "3          22  2023-12-01T00:00:00Z   \n",
            "4          23  2023-12-01T00:00:00Z   \n",
            "\n",
            "                                                tags  view_count   likes  ...  \\\n",
            "0  sidharth tv|sidharthtv|sidharth tv channel|sid...      599086   12871  ...   \n",
            "1  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...     1573530   31063  ...   \n",
            "2  neet|neet 2024|neet batch|neet batch pw|neet b...       93820    5421  ...   \n",
            "3  shopping in london|london shopping|sourav josh...     4151330  301624  ...   \n",
            "4  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...      137731    3473  ...   \n",
            "\n",
            "   videos vijay  village  vlog  vlogs  vs web with  yadav  Tag_Score  \n",
            "0       0     0        0     0      0   0   0    0      0         30  \n",
            "1       0     3        0     0      0   0   0    0      0         10  \n",
            "2       0     0        0     0      0   0   0    0      0          5  \n",
            "3       0     0        0     2      4   0   0    0      0         17  \n",
            "4       1     0        0     0      0   0   0    0      0         15  \n",
            "\n",
            "[5 rows x 119 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using XGBoost as regressor to determine most important features\n"
      ],
      "metadata": {
        "id": "HpT3RjMbIDZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv('/content/TDL DATASET - Sheet1.csv')  # Replace 'minmax_scaled_dataset.csv' with the actual file path\n",
        "\n",
        "# Drop non-numeric columns\n",
        "non_numeric_columns = ['video_id', 'title', 'publishedAt', 'channelId', 'channelTitle']\n",
        "df_numeric = df.drop(non_numeric_columns, axis=1)\n",
        "\n",
        "# Exclude specified columns from feature selection\n",
        "exclude_columns = [\"trending_date\", \"tags\", \"thumbnail_link\", \"comments_disabled\", \"ratings_disabled\", \"Is_Live_Stream\", \"Top_Comments\"]\n",
        "features_for_selection = [col for col in df_numeric.columns if col not in exclude_columns and col != \"likes\"]\n",
        "\n",
        "# Extract features and target variable\n",
        "X = df_numeric[features_for_selection]\n",
        "y = df_numeric[\"likes\"]  # Likes column as target variable\n",
        "\n",
        "# Train XGBoost model for feature selection\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
        "                           max_depth=5, alpha=10, n_estimators=10)  # You can adjust hyperparameters as needed\n",
        "\n",
        "# Fit the model to get feature importances\n",
        "xg_reg.fit(X, y)\n",
        "\n",
        "# Get selected features based on importance\n",
        "selected_features_xgboost = [feature for feature, importance in zip(X.columns, xg_reg.feature_importances_) if importance > 0]\n",
        "\n",
        "# Print selected features\n",
        "print(\"Selected Features (XGBoost):\", selected_features_xgboost)"
      ],
      "metadata": {
        "id": "pbGgSAL6HTNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11329b2-bef8-43f4-8e09-61af22fcb736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features (XGBoost): ['categoryId', 'view_count', 'comment_count', 'Subscriber_Count']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code converts publishedAT & Trending_date into the same format"
      ],
      "metadata": {
        "id": "STNKi970JAjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'publishedAt' and 'trending_date' to datetime objects\n",
        "existing_df = pd.read_csv('/dataset_category_encoded (1).csv')\n",
        "existing_df['publishedAt'] = pd.to_datetime(existing_df['publishedAt'])\n",
        "existing_df['trending_date'] = pd.to_datetime(existing_df['trending_date']).dt.date  # Extract date portion\n",
        "\n",
        "# Calculate time till trend\n",
        "existing_df['time_till_trend'] = (existing_df['trending_date'] - existing_df['publishedAt'].dt.date).dt.days\n",
        "\n",
        "existing_df.to_csv('/dataset_category_encoded (1).csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(existing_df)"
      ],
      "metadata": {
        "id": "n3ihhRJIavK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6a8eca-ac6f-4208-b07a-0f7c7447ccab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         video_id                                              title  \\\n",
            "0     9TFJ9fSirB8  APARAJITA - Full Episode - 562 | ‡¨Ö‡¨™‡¨∞‡¨æ‡¨ú‡¨ø‡¨§‡¨æ | Od...   \n",
            "1     Sm7fButI6lU        Mahanadhi | 30th Nov & 1st Dec 2023 - Promo   \n",
            "2     R-sh22bAAA4  ‡§Ö‡§¨ AARAMBH NEET 2024 ‡§ï‡§æ ‡§π‡•ã‡§ó‡§æ AAGAAZ‚Ä¶‚Ä¶ üî•üöÄ #Aara...   \n",
            "3     4u92ooRjKzc  School Se Lene  Gaya Piyush Kunali Ko üòç Super ...   \n",
            "4     tU6O2XBOjro  Girls College Bunk | EMI Rani | ( Check Descri...   \n",
            "...           ...                                                ...   \n",
            "1416  6YfvMXjn32c   PAYAL OR GOLU KHOLENGI SAARE RAAZ | Armaan Malik   \n",
            "1417  bALYalNOuCA  ‡¥á‡¥®‡µç‡¥®‡µÅ‡¥Ç ‡¥ï‡¥≥‡¥ø ‡¥®‡¥ü‡¥®‡µç‡¥®‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥ï‡¥ø‡¥∞‡µÄ‡¥ü‡¥Ç ‡¥Ü‡µº‡¥ï‡µç‡¥ï‡µç ‡¥≤‡¥≠‡¥ø‡¥ï‡µç...   \n",
            "1418  CTpzqNLjudk        Inside the Great Barrier Reef of Australia!   \n",
            "1419  zWLe3MDr68k  Bharat Mata Ki Jai' slogans reverberate in new...   \n",
            "1420  xECqx8V730k  I went to EVERY Unique Cafe in the World!! *‡§¶‡•Å...   \n",
            "\n",
            "             publishedAt                 channelId        channelTitle  \\\n",
            "0    2023-11-30 13:27:52  UCbBWncD3X_dfXwxmj4KwJnA        Sidharrth TV   \n",
            "1    2023-11-30 07:50:38  UCvrhwpnp2DHYQ1CbXby9ypQ    Vijay Television   \n",
            "2    2023-11-30 06:45:01  UCD16eo98AXl-9T61Xd711kQ  Competition Wallah   \n",
            "3    2023-11-30 02:30:02  UCjvgGbPPn-FgYeguc5nxG4A  Sourav Joshi Vlogs   \n",
            "4    2023-11-29 12:30:29  UCUKv9os4AZolovN8AS6yyBw            EMI Rani   \n",
            "...                  ...                       ...                 ...   \n",
            "1416 2023-05-29 04:30:04  UCum5kIr4aqgn9Dc21JdYCWA        Armaan Malik   \n",
            "1417 2023-05-29 03:20:00  UCArhEll4tCEN9Omjt75NYxA   Raf Talks Cricket   \n",
            "1418 2023-05-28 13:37:20  UCjNgqJ_FMLntYVzq7daw1TQ  Dhruv Rathee Vlogs   \n",
            "1419 2023-05-28 07:01:22  UCtFQDgA8J8_iiwc5-KoAQlg            ANI News   \n",
            "1420 2023-05-28 05:45:08  UCBu8GHpHy9vX8ixdTb38kIQ       Pragati Verma   \n",
            "\n",
            "     trending_date                                               tags  \\\n",
            "0       2023-12-01  sidharth tv|sidharthtv|sidharth tv channel|sid...   \n",
            "1       2023-12-01  Mahanathi|Star|Star Vijay TV|Vijay TV|Vijay|Re...   \n",
            "2       2023-12-01  neet|neet 2024|neet batch|neet batch pw|neet b...   \n",
            "3       2023-12-01  shopping in london|london shopping|sourav josh...   \n",
            "4       2023-12-01  EMI Rani|Emi Rani Youtube Channel|Emi Rani cha...   \n",
            "...            ...                                                ...   \n",
            "1416    2023-05-30                                             [None]   \n",
            "1417    2023-05-30  CSK vs GT|GT vs CSK|IPL|Indian premier league|...   \n",
            "1418    2023-06-02  Dhruv rathee|Dhruv Rathee vlogs|Dhruv Rathee v...   \n",
            "1419    2023-05-29  pm modi|new parliament building|new parliament...   \n",
            "1420    2023-06-01  Pragati verma|Pragati verma new video|Pragati ...   \n",
            "\n",
            "      view_count   likes  comment_count  ... Gaming  Howto & Style  Music  \\\n",
            "0         599086   12871            172  ...      0              0      0   \n",
            "1        1573530   31063            425  ...      0              0      0   \n",
            "2          93820    5421            522  ...      0              0      0   \n",
            "3        4151330  301624           8074  ...      0              0      0   \n",
            "4         137731    3473            101  ...      0              0      0   \n",
            "...          ...     ...            ...  ...    ...            ...    ...   \n",
            "1416     1310597   46580           2205  ...      0              0      0   \n",
            "1417       58363    3183            280  ...      0              0      0   \n",
            "1418      768503   36439           2435  ...      0              0      0   \n",
            "1419      876956   17718           1851  ...      0              0      0   \n",
            "1420     2146347   90091           6833  ...      0              0      0   \n",
            "\n",
            "      News & Politics  People & Blogs Science & Technology  Sports  \\\n",
            "0                   0               0                    0       0   \n",
            "1                   0               0                    0       0   \n",
            "2                   0               0                    0       0   \n",
            "3                   0               1                    0       0   \n",
            "4                   0               0                    0       0   \n",
            "...               ...             ...                  ...     ...   \n",
            "1416                0               1                    0       0   \n",
            "1417                0               0                    0       1   \n",
            "1418                0               1                    0       0   \n",
            "1419                1               0                    0       0   \n",
            "1420                0               0                    0       0   \n",
            "\n",
            "      Travel & Events  Sentiment_Scores  time_till_trend  \n",
            "0                   0          0.161818                1  \n",
            "1                   0          0.217500                1  \n",
            "2                   0          0.097727                1  \n",
            "3                   0          0.151449                1  \n",
            "4                   0          0.215436                2  \n",
            "...               ...               ...              ...  \n",
            "1416                0          0.344304                1  \n",
            "1417                0          0.072727                1  \n",
            "1418                0          0.265068                5  \n",
            "1419                0          0.289480                1  \n",
            "1420                0          0.441667                4  \n",
            "\n",
            "[1421 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below snippet uses min-max normalisation to standardize the dataset"
      ],
      "metadata": {
        "id": "35qZiQ5uG7VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"dataset_category_encoded_final.csv\")\n",
        "\n",
        "# Select columns to be normalized\n",
        "columns_to_normalize = ['view_count', 'comment_count', 'Sentiment_Scores', 'time_till_trend', 'Subscriber_Count']\n",
        "\n",
        "# Apply min-max normalization\n",
        "df[columns_to_normalize] = (df[columns_to_normalize] - df[columns_to_normalize].min()) / (df[columns_to_normalize].max() - df[columns_to_normalize].min())\n",
        "\n",
        "# Keep the \"likes\" column and normalized columns\n",
        "columns_to_keep = ['likes'] + columns_to_normalize\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "# Save the modified dataset to a new CSV file\n",
        "df.to_csv(\"likes_and_normalized_columns.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "aBNvtM8t33R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet applies random forest after splitting the data into Test and Train dataframes. The features used to predict the likes are :\n",
        " 'view_count', 'comment_count', 'Sentiment_Scores', 'time_till_trend', 'Subscriber_Count'. RMSE, R^2 and MAE are used to validate the predicted likes."
      ],
      "metadata": {
        "id": "s2ImwUGAC856"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"/content/likes_and_normalized_columns.csv\")\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['view_count', 'comment_count', 'Sentiment_Scores', 'time_till_trend', 'Subscriber_Count']]\n",
        "y = df['likes']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest regressor\n",
        "rf_model = RandomForestRegressor()\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Calculate R-squared value\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(\"R-squared value:\", r_squared)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "# Store predicted likes in a new column\n",
        "X_test['predicted_likes'] = y_pred\n",
        "\n",
        "# Concatenate the original 'likes' column with the DataFrame containing predicted likes\n",
        "result_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Save the dataframe to a new CSV file\n",
        "result_df.to_csv(\"predicted_likes_with_original_rf.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQUB14LM8mnj",
        "outputId": "e252aabd-7fa9-4aca-bedc-1d97cecfb069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 195179.4082651223\n",
            "R-squared value: 0.8744729310420721\n",
            "MAE: 37743.68140350877\n",
            "MAPE: 0.6260529721525804\n",
            "MSE: 38095001410.72329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet applies an ensemble model in the form of XGboost after splitting the data into Test and Train dataframes. The features used to predict the likes are :\n",
        " 'view_count', 'comment_count', 'Sentiment_Scores', 'time_till_trend', 'Subscriber_Count'. RMSE, R^2 and MAE are used to validate the predicted likes."
      ],
      "metadata": {
        "id": "1_uGX7RoGj6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"/content/likes_and_normalized_columns.csv\")\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['view_count', 'comment_count', 'Sentiment_Scores', 'time_till_trend', 'Subscriber_Count']]\n",
        "y = df['likes']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost regressor\n",
        "xgb_model = XGBRegressor()\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Calculate R-squared value\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(\"R-squared value:\", r_squared)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "\n",
        "# Store predicted likes in a new column\n",
        "X_test['predicted_likes'] = y_pred\n",
        "\n",
        "# Concatenate the original 'likes' column with the DataFrame containing predicted likes\n",
        "result_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Save the dataframe to a new CSV file\n",
        "result_df.to_csv(\"predicted_likes_with_original.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy6vbmmL7pdB",
        "outputId": "93d16a8b-7ec9-418b-cebe-76f9a69d780f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 110538.93938925382\n",
            "R-squared value: 0.9597375701889096\n",
            "MAE: 31216.7363869918\n",
            "MSE: 12218857121.30113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xg Boost Regressor provides the best results"
      ],
      "metadata": {
        "id": "NPfKsYlqGso2"
      }
    }
  ]
}